# these should be in order of publication date
-
  name: Adversarial Logit Pairing
  url: https://arxiv.org/abs/1803.06373
  authors: Kannan et al.
  code: https://github.com/labsix/adversarial-logit-pairing-analysis
  dataset: ImageNet
  threat_model: $$\ell_\infty (\epsilon = 16/255)$$
  natural: 72%
  claims: >
    27.9% accuracy
  analyses:
    - claims: 0.1% accuracy
      citation: EIA18
      url: https://arxiv.org/abs/1807.10272
      code: https://github.com/labsix/adversarial-logit-pairing-analysis
      note: >
        This analysis has been performed on the ImageNet 64x64 model released
        at
        https://&#8203;github.com/&#8203;tensorflow/&#8302;models/&#8302;tree/&#8302;master/&#8302;research/&#8302;adversarial_logit_pairing.
        The authors claim to have unreleased models that may be more secure.
        
-
  name: Combatting and detecting FGSM and PGD adversarial noise
  url: https://jngannon.github.io/FGSM_Article
  authors: James Gannon
  code: https://github.com/jngannon/robustml-test-analysis
  dataset: MNIST
  threat_model: $$\ell_\infty (\epsilon = 0.1)$$
  natural: 98.2%
  claims: >
    78.2% accuracy
  analyses:
    
